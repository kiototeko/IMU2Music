# IMU2Music: Learning to Generate Music from IMU Sensor Readings

In this project we will be exploring a way to generate music given IMU readings from a person playing an instrument.

## Project Goal and Vision

Explore different neural network architectures in the task of generating music from IMU readings present in performers' bodies.

With the advent of diverse neural network architectures for the task of processing time sequences, in the form of Recurrent Neural Networks (RNNs) and the variants that have been created since its inception, like Long Short-Term Memory (LSTM) architectures and transformers, among others, a plethora of uses have been engineered for these types of networks that go beyond classification tasks, like machine translation which convert one sequence of inputs into another, usually language-related. A further development has seen the creation of networks that translate a sequence from one sensor modality to another, which is the task we are undertaking in this project.

## Specific Aims

1. Obtain a dataset that captures musicians motion while performing, using Intertial Motion Sensors.
2. Design an extension to the musical transformer network used in previous works so as to include IMU data.
3. Test different architectures for the encoder part and compare quantitative and qualitative results.

For more information visit the [website](https://kiototeko.github.io/IMU2Music/).

## More Information

* The audio recordings generated by the model can be accessed at **data/recordings**, check the website to understand what they correspond to.
* To download the TELMI dataset you can use the program **code/getDataset.py**, this will put all files in the **data** directory and from them, you can run the program **data/process_data.sh** to collect all data into a few directories.
* You can also directly download the dataset from [here](https://drive.google.com/file/d/1vhTIwrRSaCS34HZ3BVba0P6FgPPbeb-e/view?usp=sharing).
* To run the neural network, download the forked [repository](https://github.com/kiototeko/Foley-Music) at **code/Foley-Music** and read the instructions there.
