# IMU2Music: Learning to Generate Music from IMU Sensor Readings

In this project we will be exploring a way to generate music given IMU readings from a person playing an instrument.

## Project Goal and Vision

Explore different neural network architectures in the task of generating music from IMU readings present in performers' bodies.

With the advent of diverse neural network architectures for the task of processing time sequences, in the form of Recurrent Neural Networks (RNNs) and the variants that have been created since its inception, like Long Short-Term Memory (LSTM) architectures and transformers, among others, a plethora of uses have been engineered for these types of networks that go beyond classification tasks, like machine translation which convert one sequence of inputs into another, usually language-related. A further development has seen the creation of networks that translate a sequence from one sensor modality to another, which is the task we are undertaking in this project.

## Specific Aims

1. Obtain a dataset that captures musicians motion while performing, using Intertial Motion Sensors.
2. Design an extension to the musical transformer network used in both \[[4](#references)\] and \[[8](#references)\] so as to include IMU data
3. Test its accuracy compared to the previous networks

For more information visit the website.
